{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c9e219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4c289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgElon = face_recognition.load_image_file('Images/Elon.jpeg')\n",
    "imgElon = cv2.cvtColor(imgElon, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "imgtest = face_recognition.load_image_file('Images/Elon 2.jpeg')\n",
    "imgtest = cv2.cvtColor(imgtest, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "imgbill = face_recognition.load_image_file('Images/Bill 2.jpeg')\n",
    "imgbill = cv2.cvtColor(imgbill, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b2126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  8,  95, 162],\n",
       "        [  6,  96, 161],\n",
       "        [  4,  97, 160],\n",
       "        ...,\n",
       "        [ 10,  26,  49],\n",
       "        [ 15,  32,  58],\n",
       "        [ 21,  39,  68]],\n",
       "\n",
       "       [[  9,  96, 163],\n",
       "        [  7,  97, 162],\n",
       "        [  2,  96, 161],\n",
       "        ...,\n",
       "        [ 10,  26,  49],\n",
       "        [ 15,  32,  58],\n",
       "        [ 21,  39,  68]],\n",
       "\n",
       "       [[ 10,  97, 164],\n",
       "        [  6,  98, 163],\n",
       "        [  3,  97, 162],\n",
       "        ...,\n",
       "        [ 10,  26,  49],\n",
       "        [ 15,  32,  58],\n",
       "        [ 21,  39,  68]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 33, 130, 193],\n",
       "        [ 31, 130, 192],\n",
       "        [ 28, 129, 191],\n",
       "        ...,\n",
       "        [ 40,  56,  69],\n",
       "        [ 43,  59,  72],\n",
       "        [ 44,  60,  73]],\n",
       "\n",
       "       [[ 34, 131, 194],\n",
       "        [ 33, 132, 194],\n",
       "        [ 30, 131, 193],\n",
       "        ...,\n",
       "        [ 40,  56,  69],\n",
       "        [ 43,  59,  72],\n",
       "        [ 44,  60,  73]],\n",
       "\n",
       "       [[ 34, 131, 194],\n",
       "        [ 32, 131, 193],\n",
       "        [ 30, 131, 193],\n",
       "        ...,\n",
       "        [ 40,  56,  69],\n",
       "        [ 43,  59,  72],\n",
       "        [ 44,  60,  73]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the face location and encode the image\n",
    "faceloc =  face_recognition.face_locations(imgElon)[0] #Find the first face location\n",
    "#Encode the image\n",
    "encodeElon = face_recognition.face_encodings(imgElon)[0]\n",
    "cv2.rectangle(imgElon, (faceloc[3], faceloc[0]), (faceloc[1], faceloc[2]), (255, 0, 255), 2) #Draw a rectangle around the face\n",
    "\n",
    "\n",
    "print(faceloc) #Print the face location which is a list of 4 values [top, right, bottom, left]\n",
    "\n",
    "#Find the face location and encode the image\n",
    "faceloctest =  face_recognition.face_locations(imgtest)[0] #Find the first face location\n",
    "#Encode the image\n",
    "encodetest = face_recognition.face_encodings(imgtest)[0]\n",
    "#Draw a rectangle around the face\n",
    "cv2.rectangle(imgtest, (faceloc[3], faceloc[0]), (faceloc[1], faceloc[2]), (255, 0, 255), 2) \n",
    "\n",
    "\n",
    "#Do the same for Bill images\n",
    "\n",
    "#Find the face location and encode the image\n",
    "facelocbill =  face_recognition.face_locations(imgbill)[0] #Find the first face location\n",
    "#Encode the image\n",
    "encodebill = face_recognition.face_encodings(imgbill)[0]\n",
    "#Draw a rectangle around the face\n",
    "cv2.rectangle(imgbill, (faceloc[3], faceloc[0]), (faceloc[1], faceloc[2]), (255, 0, 255), 2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2ab7e",
   "metadata": {},
   "source": [
    "### Now we Compare the Encodings using the linear SVM to find if they match or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f407b2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36853893]\n",
      "[True]\n",
      "[0.79852846]\n",
      "[False]\n"
     ]
    }
   ],
   "source": [
    "reslts = face_recognition.compare_faces([encodeElon], encodetest) #Compare the two images\n",
    "facedist = face_recognition.face_distance([encodeElon], encodetest) #Find the distance between the two images\n",
    "print(facedist) #Print the distance between the two images\n",
    "print(reslts) #Print the result which is a list of boolean values\n",
    "\n",
    "#For test with bill gates img\n",
    "reslts_bill = face_recognition.compare_faces([encodeElon], encodebill) #Compare the two images\n",
    "facedist_bill = face_recognition.face_distance([encodeElon], encodebill) #Find the distance between the two images\n",
    "print(facedist_bill) #Print the distance between the two images\n",
    "print(reslts_bill) #Print the result which is a list of boolean values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed316bb9",
   "metadata": {},
   "source": [
    "### Notes\n",
    "Note that if you used Bill img as a Test img it will gives you False\n",
    "And the distance is very different if they match or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebbd6086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.putText(imgtest, f'{reslts[0]} {round(facedist[0], 2)}', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2) #Put the result on the image\n",
    "cv2.putText(imgbill, f'{reslts_bill[0]} {round(facedist_bill[0], 2)}', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2) #Put the result on the image    \n",
    "cv2.imshow('Bill', imgbill)\n",
    "cv2.imshow('Elon', imgElon)\n",
    "cv2.imshow('Test', imgtest)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd7589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
